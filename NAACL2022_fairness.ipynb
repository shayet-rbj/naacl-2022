{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtgbrM76oD9s"
      },
      "source": [
        "# ACL 2022 Submission: Fairness Calculations\n",
        "\n",
        "The input required here is the merged prediction files, and the gold standard data with the relevant demographic information.\n",
        "\n",
        "Output is a spreadsheet with calculated intersectional DI scores.\n",
        "\n",
        "## Setup\n",
        "\n",
        "First the following upgrades are required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75mLLOyW_lBE",
        "outputId": "903f497e-0e54-44bd-e7bd-4b41f29725e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Collecting tzdata>=2022.1 (from pandas)\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Installing collected packages: tzdata, pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.0.3 tzdata-2023.3\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.0.10)\n",
            "Collecting openpyxl\n",
            "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.0/250.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Installing collected packages: openpyxl\n",
            "  Attempting uninstall: openpyxl\n",
            "    Found existing installation: openpyxl 3.0.10\n",
            "    Uninstalling openpyxl-3.0.10:\n",
            "      Successfully uninstalled openpyxl-3.0.10\n",
            "Successfully installed openpyxl-3.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pandas\n",
        "!pip install --upgrade openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install aif360"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAdv8EDsW6e8",
        "outputId": "b2c96977-69fd-46b6-c700-57fc861216b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aif360\n",
            "  Downloading aif360-0.5.0-py3-none-any.whl (214 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/214.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m153.6/214.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.1/214.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from aif360) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from aif360) (1.10.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from aif360) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from aif360) (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from aif360) (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360) (2022.7.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360) (2023.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->aif360) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->aif360) (3.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->aif360) (1.16.0)\n",
            "Installing collected packages: aif360\n",
            "Successfully installed aif360-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install 'aif360[LawSchoolGPA]'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leso3T2WW8-C",
        "outputId": "57999b29-5133-457c-a00d-c923596eea1f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: aif360[LawSchoolGPA] in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from aif360[LawSchoolGPA]) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from aif360[LawSchoolGPA]) (1.10.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from aif360[LawSchoolGPA]) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from aif360[LawSchoolGPA]) (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from aif360[LawSchoolGPA]) (3.7.1)\n",
            "Collecting tempeh (from aif360[LawSchoolGPA])\n",
            "  Downloading tempeh-0.1.12-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360[LawSchoolGPA]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360[LawSchoolGPA]) (2022.7.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360[LawSchoolGPA]) (2023.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->aif360[LawSchoolGPA]) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->aif360[LawSchoolGPA]) (3.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360[LawSchoolGPA]) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360[LawSchoolGPA]) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360[LawSchoolGPA]) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360[LawSchoolGPA]) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360[LawSchoolGPA]) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360[LawSchoolGPA]) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360[LawSchoolGPA]) (3.1.0)\n",
            "Collecting memory-profiler (from tempeh->aif360[LawSchoolGPA])\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from tempeh->aif360[LawSchoolGPA]) (7.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tempeh->aif360[LawSchoolGPA]) (2.27.1)\n",
            "Collecting shap (from tempeh->aif360[LawSchoolGPA])\n",
            "  Downloading shap-0.42.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.9/547.9 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->aif360[LawSchoolGPA]) (1.16.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory-profiler->tempeh->aif360[LawSchoolGPA]) (5.9.5)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from pytest->tempeh->aif360[LawSchoolGPA]) (23.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->tempeh->aif360[LawSchoolGPA]) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->tempeh->aif360[LawSchoolGPA]) (1.2.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->tempeh->aif360[LawSchoolGPA]) (1.1.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->tempeh->aif360[LawSchoolGPA]) (2.0.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tempeh->aif360[LawSchoolGPA]) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tempeh->aif360[LawSchoolGPA]) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->tempeh->aif360[LawSchoolGPA]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tempeh->aif360[LawSchoolGPA]) (3.4)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap->tempeh->aif360[LawSchoolGPA]) (4.65.0)\n",
            "Collecting slicer==0.0.7 (from shap->tempeh->aif360[LawSchoolGPA])\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap->tempeh->aif360[LawSchoolGPA]) (0.56.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap->tempeh->aif360[LawSchoolGPA]) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap->tempeh->aif360[LawSchoolGPA]) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->shap->tempeh->aif360[LawSchoolGPA]) (67.7.2)\n",
            "Installing collected packages: slicer, memory-profiler, shap, tempeh\n",
            "Successfully installed memory-profiler-0.61.0 shap-0.42.1 slicer-0.0.7 tempeh-0.1.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnDc1XIiXCCb",
        "outputId": "d2dee09d-7580-4a22-c3e5-4071f37f5ff4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip gdrive/My\\ Drive/Data/train.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10JRXWd0XJDv",
        "outputId": "cf67987a-7217-4386-9dfd-26f2ca5892ba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  gdrive/My Drive/Data/train.zip\n",
            "   creating: train/\n",
            "  inflating: train/trainHS.csv       \n",
            "  inflating: __MACOSX/train/._trainHS.csv  \n",
            "  inflating: train/Data_SurveyPlusDemographics.txt  \n",
            "  inflating: __MACOSX/train/._Data_SurveyPlusDemographics.txt  \n",
            "  inflating: train/.DS_Store         \n",
            "  inflating: __MACOSX/train/._.DS_Store  \n",
            "  inflating: train/testHS.csv        \n",
            "  inflating: __MACOSX/train/._testHS.csv  \n",
            "  inflating: train/validHS.csv       \n",
            "  inflating: __MACOSX/train/._validHS.csv  \n",
            "  inflating: train/fipi.csv          \n",
            "  inflating: __MACOSX/train/._fipi.csv  \n",
            "   creating: train/merged/\n",
            "  inflating: __MACOSX/train/._merged  \n",
            "  inflating: train/merged/MBTI_thinking_Binary_PTD_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTI_thinking_Binary_PTD_CNN_test.csv  \n",
            "  inflating: train/merged/MBTIShort_perceiving_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTIShort_perceiving_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/Psychometric_Numeracy_Continuous_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_Numeracy_Continuous_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/MBTIShort_perceiving_Binary_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTIShort_perceiving_Binary_PT_BERT_test.csv  \n",
            "  inflating: train/merged/FIPI_Openness_Binary_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Openness_Binary_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/MBTI_perceiving_Binary_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTI_perceiving_Binary_PT_BERT_test.csv  \n",
            "  inflating: train/merged/Psychometric_SubjectiveLit_Continuous_PTD_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_SubjectiveLit_Continuous_PTD_CNN_test.csv  \n",
            "  inflating: train/merged/MBTI_intuitive_Binary_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTI_intuitive_Binary_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/FIPI_Extraverted_Binary_PT_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Extraverted_Binary_PT_CNN_test.csv  \n",
            "  inflating: train/merged/MBTI_intuitive_Binary_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTI_intuitive_Binary_PT_BERT_test.csv  \n",
            "  inflating: train/merged/FIPI_Openness_Continuous_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Openness_Continuous_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/FIPI_Dependable_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Dependable_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPI_Agreeable_Continuous_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Agreeable_Continuous_PT_BERT_test.csv  \n",
            "  inflating: train/merged/AskAPatient_AskAPatient_Continuous_PTD_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._AskAPatient_AskAPatient_Continuous_PTD_CNN_test.csv  \n",
            "  inflating: train/merged/FIPIShort_Extraverted_Binary_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPIShort_Extraverted_Binary_PT_BERT_test.csv  \n",
            "  inflating: train/merged/Psychometric_SubjectiveLit_Binary_PT_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_SubjectiveLit_Binary_PT_CNN_test.csv  \n",
            "  inflating: train/merged/FIPI_Agreeable_Binary_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Agreeable_Binary_PT_BERT_test.csv  \n",
            "  inflating: train/merged/MBTIShort_thinking_Binary_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTIShort_thinking_Binary_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/FIPI_Stable_Continuous_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Stable_Continuous_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/Psychometric_TrustPhys_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_TrustPhys_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/Psychometric_Anxiety_Continuous_PTD_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_Anxiety_Continuous_PTD_CNN_test.csv  \n",
            "  inflating: train/merged/FIPI_Stable_Continuous_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Stable_Continuous_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/Psychometric_SubjectiveLit_Binary_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_SubjectiveLit_Binary_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/AskAPatient_AskAPatient_Binary_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._AskAPatient_AskAPatient_Binary_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/FIPI_Dependable_Continuous_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Dependable_Continuous_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPI_Openness_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Openness_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/Hatespeech_HateSpeech_Binary_PTD_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Hatespeech_HateSpeech_Binary_PTD_CNN_test.csv  \n",
            "  inflating: train/merged/Psychometric_Numeracy_Binary_PTD_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_Numeracy_Binary_PTD_CNN_test.csv  \n",
            "  inflating: train/merged/MBTIShort_thinking_Binary_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTIShort_thinking_Binary_PT_BERT_test.csv  \n",
            "  inflating: train/merged/FIPI_Dependable_Binary_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Dependable_Binary_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/AskAPatient_AskAPatient_Binary_PTD_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._AskAPatient_AskAPatient_Binary_PTD_CNN_test.csv  \n",
            "  inflating: train/merged/.DS_Store  \n",
            "  inflating: __MACOSX/train/merged/._.DS_Store  \n",
            "  inflating: train/merged/FIPI_Dependable_Continuous_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Dependable_Continuous_PT_BERT_test.csv  \n",
            "  inflating: train/merged/Psychometric_Anxiety_Binary_PTD_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_Anxiety_Binary_PTD_CNN_test.csv  \n",
            "  inflating: train/merged/Psychometric_TrustPhys_Binary_PTD_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_TrustPhys_Binary_PTD_CNN_test.csv  \n",
            "  inflating: train/merged/MBTIShort_thinking_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTIShort_thinking_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/Psychometric_SubjectiveLit_Continuous_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_SubjectiveLit_Continuous_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/MBTI_perceiving_Binary_PT_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTI_perceiving_Binary_PT_CNN_test.csv  \n",
            "  inflating: train/merged/FIPI_Stable_Binary_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Stable_Binary_PT_BERT_test.csv  \n",
            "  inflating: train/merged/FIPI_Agreeable_Continuous_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Agreeable_Continuous_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/Hatespeech_HateSpeech_Binary_PT_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Hatespeech_HateSpeech_Binary_PT_CNN_test.csv  \n",
            "  inflating: train/merged/FIPIShort_Stable_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPIShort_Stable_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPIShort2_Extraverted_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPIShort2_Extraverted_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPI_Extraverted_Continuous_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Extraverted_Continuous_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/FIPIShort_Extraverted_Binary_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPIShort_Extraverted_Binary_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/FIPIShort_Stable_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPIShort_Stable_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/Psychometric_Anxiety_Binary_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_Anxiety_Binary_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/Hatespeech_Hatespeech_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Hatespeech_Hatespeech_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/Psychometric_Numeracy_Continuous_PTD_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_Numeracy_Continuous_PTD_CNN_test.csv  \n",
            "  inflating: train/merged/MBTI_intuitive_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTI_intuitive_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPIShort_Stable_Continuous_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPIShort_Stable_Continuous_PT_BERT_test.csv  \n",
            "  inflating: train/merged/FIPI_Stable_Continuous_PT_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Stable_Continuous_PT_CNN_test.csv  \n",
            "  inflating: train/merged/Psychometric_TrustPhys_Continuous_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_TrustPhys_Continuous_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPI_Stable_Binary_PT_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Stable_Binary_PT_CNN_test.csv  \n",
            "  inflating: train/merged/Psychometric_TrustPhys_Binary_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_TrustPhys_Binary_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/FIPI_Extraverted_Continuous_PTD_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Extraverted_Continuous_PTD_CNN_test.csv  \n",
            "  inflating: train/merged/Psychometric_Numeracy_Continuous_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_Numeracy_Continuous_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPI_Extraverted_Continuous_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Extraverted_Continuous_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPI_Dependable_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Dependable_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/Psychometric_Numeracy_Continuous_PT_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_Numeracy_Continuous_PT_CNN_test.csv  \n",
            "  inflating: train/merged/Psychometric_TrustPhys_Continuous_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_TrustPhys_Continuous_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/FIPI_Extraverted_Continuous_PT_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Extraverted_Continuous_PT_CNN_test.csv  \n",
            "  inflating: train/merged/Psychometric_SubjectiveLit_Binary_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_SubjectiveLit_Binary_PT_BERT_test.csv  \n",
            "  inflating: train/merged/Psychometric_Numeracy_Binary_PT_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_Numeracy_Binary_PT_CNN_test.csv  \n",
            "  inflating: train/merged/FIPI_Stable_Continuous_PTD_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Stable_Continuous_PTD_CNN_test.csv  \n",
            "  inflating: train/merged/Psychometric_SubjectiveLit_Continuous_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_SubjectiveLit_Continuous_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/Psychometric_TrustPhys_Continuous_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_TrustPhys_Continuous_PT_BERT_test.csv  \n",
            "  inflating: train/merged/FIPI_Extraverted_Binary_PTD_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Extraverted_Binary_PTD_CNN_test.csv  \n",
            "  inflating: train/merged/FIPI_Extraverted_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Extraverted_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/AskAPatient_AskAPatient_Continuous_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._AskAPatient_AskAPatient_Continuous_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/Psychometric_Numeracy_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_Numeracy_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPIShort2_Extraverted_Binary_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPIShort2_Extraverted_Binary_PT_BERT_test.csv  \n",
            "  inflating: train/merged/Hatespeech_Hatespeech_Binary_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Hatespeech_Hatespeech_Binary_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/FIPIShort2_Extraverted_Binary_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPIShort2_Extraverted_Binary_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/FIPI_Openness_Binary_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Openness_Binary_PT_BERT_test.csv  \n",
            "  inflating: train/merged/Psychometric_Numeracy_Continuous_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_Numeracy_Continuous_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/MBTI_thinking_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTI_thinking_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPI_Agreeable_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Agreeable_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPI_Stable_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Stable_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPI_Extraverted_Binary_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Extraverted_Binary_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/Psychometric_Anxiety_Continuous_PT_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_Anxiety_Continuous_PT_CNN_test.csv  \n",
            "  inflating: train/merged/MBTIShort_perceiving_Binary_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTIShort_perceiving_Binary_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/MBTI_perceiving_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTI_perceiving_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPIShort_Stable_Binary_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPIShort_Stable_Binary_PT_BERT_test.csv  \n",
            "  inflating: train/merged/MBTI_introverted_Binary_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTI_introverted_Binary_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/FIPI_Stable_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Stable_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPI_Stable_Continuous_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Stable_Continuous_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/Psychometric_TrustPhys_Continuous_PT_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_TrustPhys_Continuous_PT_CNN_test.csv  \n",
            "  inflating: train/merged/Psychometric_Anxiety_Continuous_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_Anxiety_Continuous_PT_BERT_test.csv  \n",
            "  inflating: train/merged/MBTI_perceiving_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTI_perceiving_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPI_Agreeable_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Agreeable_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/AskAPatient_AskAPatient_Continuous_PT_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._AskAPatient_AskAPatient_Continuous_PT_CNN_test.csv  \n",
            "  inflating: train/merged/AskAPatient_AskAPatient_Continuous_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._AskAPatient_AskAPatient_Continuous_PT_BERT_test.csv  \n",
            "  inflating: train/merged/FIPIShort2_Stable_Binary_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPIShort2_Stable_Binary_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/FIPIShort2_Stable_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPIShort2_Stable_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPI_Agreeable_Binary_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Agreeable_Binary_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/FIPI_Openness_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Openness_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPI_Dependable_Continuous_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Dependable_Continuous_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/Psychometric_Anxiety_Continuous_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_Anxiety_Continuous_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPIShort2_Stable_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPIShort2_Stable_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/Psychometric_SubjectiveLit_Continuous_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_SubjectiveLit_Continuous_PT_BERT_test.csv  \n",
            "  inflating: train/merged/MBTI_perceiving_Binary_PTD_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTI_perceiving_Binary_PTD_CNN_test.csv  \n",
            "  inflating: train/merged/FIPI_Stable_Binary_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Stable_Binary_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/MBTI_thinking_Binary_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTI_thinking_Binary_PT_BERT_test.csv  \n",
            "  inflating: train/merged/MBTI_thinking_Binary_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTI_thinking_Binary_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/MBTI_introverted_Binary_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTI_introverted_Binary_PT_BERT_test.csv  \n",
            "  inflating: train/merged/FIPIShort_Extraverted_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPIShort_Extraverted_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/MBTIShort_perceiving_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTIShort_perceiving_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPI_Openness_Continuous_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Openness_Continuous_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPI_Extraverted_Continuous_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Extraverted_Continuous_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPI_Stable_Binary_PTD_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Stable_Binary_PTD_CNN_test.csv  \n",
            "  inflating: train/merged/Psychometric_Numeracy_Binary_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_Numeracy_Binary_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/FIPI_Dependable_Continuous_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Dependable_Continuous_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/FIPIShort_Extraverted_Continuous_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPIShort_Extraverted_Continuous_PT_BERT_test.csv  \n",
            "  inflating: train/merged/MBTIShort_thinking_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTIShort_thinking_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/Psychometric_Numeracy_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_Numeracy_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/Psychometric_TrustPhys_Binary_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_TrustPhys_Binary_PT_BERT_test.csv  \n",
            "  inflating: train/merged/Psychometric_Anxiety_Binary_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_Anxiety_Binary_PT_BERT_test.csv  \n",
            "  inflating: train/merged/FIPIShort_Stable_Binary_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPIShort_Stable_Binary_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/Psychometric_Anxiety_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_Anxiety_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/AskAPatient_AskAPatient_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._AskAPatient_AskAPatient_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/AskAPatient_AskAPatient_Binary_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._AskAPatient_AskAPatient_Binary_PT_BERT_test.csv  \n",
            "  inflating: train/merged/Psychometric_Numeracy_Binary_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_Numeracy_Binary_PT_BERT_test.csv  \n",
            "  inflating: train/merged/Psychometric_TrustPhys_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_TrustPhys_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPIShort2_Stable_Binary_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPIShort2_Stable_Binary_PT_BERT_test.csv  \n",
            "  inflating: train/merged/FIPIShort_Extraverted_Continuous_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPIShort_Extraverted_Continuous_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/Hatespeech_Hatespeech_Binary_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Hatespeech_Hatespeech_Binary_PT_BERT_test.csv  \n",
            "  inflating: train/merged/FIPI_Extraverted_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Extraverted_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPI_Agreeable_Continuous_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Agreeable_Continuous_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPIShort_Stable_Continuous_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPIShort_Stable_Continuous_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/Hatespeech_Hatespeech_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Hatespeech_Hatespeech_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/AskAPatient_AskAPatient_Continuous_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._AskAPatient_AskAPatient_Continuous_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPIShort2_Extraverted_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPIShort2_Extraverted_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/MBTI_thinking_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTI_thinking_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/AskAPatient_AskAPatient_Continuous_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._AskAPatient_AskAPatient_Continuous_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPI_Agreeable_Continuous_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Agreeable_Continuous_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/MBTI_introverted_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTI_introverted_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/Psychometric_SubjectiveLit_Continuous_PT_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_SubjectiveLit_Continuous_PT_CNN_test.csv  \n",
            "  inflating: train/merged/FIPI_Extraverted_Continuous_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Extraverted_Continuous_PT_BERT_test.csv  \n",
            "  inflating: train/merged/Psychometric_SubjectiveLit_Continuous_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_SubjectiveLit_Continuous_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/Psychometric_Anxiety_Binary_PT_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_Anxiety_Binary_PT_CNN_test.csv  \n",
            "  inflating: train/merged/Psychometric_Anxiety_Continuous_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_Anxiety_Continuous_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/MBTI_intuitive_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTI_intuitive_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPIShort_Extraverted_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPIShort_Extraverted_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPI_Dependable_Binary_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Dependable_Binary_PT_BERT_test.csv  \n",
            "  inflating: train/merged/MBTI_perceiving_Binary_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTI_perceiving_Binary_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/FIPIShort_Stable_Continuous_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPIShort_Stable_Continuous_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPIShort_Extraverted_Continuous_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPIShort_Extraverted_Continuous_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/Psychometric_Numeracy_Continuous_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_Numeracy_Continuous_PT_BERT_test.csv  \n",
            "  inflating: train/merged/Psychometric_TrustPhys_Binary_PT_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_TrustPhys_Binary_PT_CNN_test.csv  \n",
            "  inflating: train/merged/FIPI_Openness_Continuous_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Openness_Continuous_PT_BERT_test.csv  \n",
            "  inflating: train/merged/FIPIShort_Extraverted_Continuous_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPIShort_Extraverted_Continuous_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/FIPI_Openness_Continuous_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Openness_Continuous_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/Psychometric_SubjectiveLit_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_SubjectiveLit_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/MBTI_thinking_Binary_PT_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTI_thinking_Binary_PT_CNN_test.csv  \n",
            "  inflating: train/merged/Psychometric_TrustPhys_Continuous_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_TrustPhys_Continuous_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/Psychometric_Anxiety_Continuous_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_Anxiety_Continuous_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/FIPIShort_Stable_Continuous_PTD_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPIShort_Stable_Continuous_PTD_BERT_test.csv  \n",
            "  inflating: train/merged/AskAPatient_AskAPatient_Binary_PT_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._AskAPatient_AskAPatient_Binary_PT_CNN_test.csv  \n",
            "  inflating: train/merged/FIPI_Stable_Continuous_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Stable_Continuous_PT_BERT_test.csv  \n",
            "  inflating: train/merged/Psychometric_Anxiety_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_Anxiety_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: train/merged/Psychometric_SubjectiveLit_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_SubjectiveLit_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/MBTI_introverted_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._MBTI_introverted_Binary_PT_RoBERTa_test.csv  \n",
            "  inflating: train/merged/Psychometric_TrustPhys_Continuous_PTD_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_TrustPhys_Continuous_PTD_CNN_test.csv  \n",
            "  inflating: train/merged/FIPI_Extraverted_Binary_PT_BERT_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._FIPI_Extraverted_Binary_PT_BERT_test.csv  \n",
            "  inflating: train/merged/Psychometric_SubjectiveLit_Binary_PTD_CNN_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._Psychometric_SubjectiveLit_Binary_PTD_CNN_test.csv  \n",
            "  inflating: train/merged/AskAPatient_AskAPatient_Binary_PTD_RoBERTa_test.csv  \n",
            "  inflating: __MACOSX/train/merged/._AskAPatient_AskAPatient_Binary_PTD_RoBERTa_test.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO6IMa8vE5aW"
      },
      "source": [
        "## Restart runtime after executing the above cell to get the latest version of pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-meESHofN0uc"
      },
      "source": [
        "# Psychometric and FIPI Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljhNFRHEytvn",
        "outputId": "fa047363-bbf7-4554-f1c0-b1ffa46db1cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-60e16efb8131>:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_data_fipi[['D1', 'D2', 'D3', 'D4', 'D5']] = test_data_fipi[['D1', 'D2', 'D3', 'D4', 'D5']].apply(pd.to_numeric, errors='coerce')\n",
            "<ipython-input-7-60e16efb8131>:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_data_psych[['D1', 'D2', 'D3', 'D4', 'D5']] = test_data_psych[['D1', 'D2', 'D3', 'D4', 'D5']].apply(pd.to_numeric, errors='coerce')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        1.0\n",
            "1        1.0\n",
            "2        1.0\n",
            "3        1.0\n",
            "4        1.0\n",
            "        ... \n",
            "12619    NaN\n",
            "12620    1.0\n",
            "12621    1.0\n",
            "12622    0.0\n",
            "12623    1.0\n",
            "Name: gender, Length: 83077, dtype: float64\n",
            "0        1.0\n",
            "1        1.0\n",
            "2        1.0\n",
            "3        1.0\n",
            "4        1.0\n",
            "        ... \n",
            "12618    0.0\n",
            "12620    1.0\n",
            "12621    1.0\n",
            "12622    0.0\n",
            "12623    1.0\n",
            "Name: gender, Length: 44401, dtype: float64\n",
            "42009\n",
            "['Age_Gender', 'Age_Gender_Race', 'Age_Gender_Race_Education', 'Age_Gender_Race_Income', 'Age_Gender_Education', 'Age_Gender_Education_Income', 'Age_Gender_Income', 'Age_Race', 'Age_Race_Education', 'Age_Race_Education_Income', 'Age_Race_Income', 'Age_Education', 'Age_Education_Income', 'Age_Income', 'Gender_Race', 'Gender_Race_Education', 'Gender_Race_Education_Income', 'Gender_Race_Income', 'Gender_Education', 'Gender_Education_Income', 'Gender_Income', 'Race_Education', 'Race_Education_Income', 'Race_Income', 'Education_Income', 'Age_Gender_Race_Education_Income']\n"
          ]
        }
      ],
      "source": [
        "# load libraries and data\n",
        "# to replicate on google colab just drag and drop relevant files into the directory (they do not persist)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import statistics\n",
        "\n",
        "from aif360.sklearn.metrics import disparate_impact_ratio\n",
        "from aif360.datasets import StandardDataset\n",
        "\n",
        "data = pd.read_csv('/content/train/Data_SurveyPlusDemographics.txt', sep='\\t', low_memory=False)\n",
        "# d.set_option('display.max_columns', None)\n",
        "data.to_excel(\"PsychometricData.xlsx\")\n",
        "\n",
        "# need this for psychometric data, the other ones have demographics in the files\n",
        "test_data_psych = pd.read_excel(\"PsychometricData.xlsx\", skiprows=lambda x: x in [1], header=0)\n",
        "test_data_fipi = pd.read_csv(\"/content/train/fipi.csv\", low_memory=False)\n",
        "HS_train = pd.read_csv(\"/content/train/trainHS.csv\")\n",
        "HS_valid = pd.read_csv(\"/content/train/validHS.csv\")\n",
        "HS_test = pd.read_csv(\"/content/train/testHS.csv\")\n",
        "frames = [HS_train, HS_valid, HS_test]\n",
        "test_data_HS = pd.concat(frames)\n",
        "\n",
        "test_data_psych = test_data_psych[[\"Text_Anxiety\",\"Text_Numeracy\",\"Text_SubjectiveLit\",\n",
        "            \"Text_TrustPhys\",\"Label_SubjectiveLit\",\"Label_TrustPhys\",\n",
        "            \"Label_Anxiety\",\"Label_Numeracy\",\"D1\",\n",
        "            \"D2\",\"D3\",\"D4\",\"D5\",\"D6\",\n",
        "            ]]\n",
        "\n",
        "test_data_fipi = test_data_fipi[[\"Text_Anxiety\",\"Text_Numeracy\",\"Text_SubjectiveLit\",\n",
        "            \"Text_TrustPhys\",\"Label_SubjectiveLit\",\"Label_TrustPhys\",\n",
        "            \"Label_Anxiety\",\"Label_Numeracy\",\"D1\",\n",
        "            \"D2\",\"D3\",\"D4\",\"D5\",\"D6\",\n",
        "            ]]\n",
        "\n",
        "test_data_HS = test_data_HS[[\"text\", \"gender\", \"age\",\"country\",\"ethnicity\",\"label\"]]\n",
        "\n",
        "\n",
        "test_data_fipi[['D1', 'D2', 'D3', 'D4', 'D5']] = test_data_fipi[['D1', 'D2', 'D3', 'D4', 'D5']].apply(pd.to_numeric, errors='coerce')\n",
        "test_data_psych[['D1', 'D2', 'D3', 'D4', 'D5']] = test_data_psych[['D1', 'D2', 'D3', 'D4', 'D5']].apply(pd.to_numeric, errors='coerce')\n",
        "test_data_HS[[\"gender\", \"age\",\"ethnicity\",\"label\"]] = test_data_HS[[\"gender\", \"age\",\"ethnicity\",\"label\"]].apply(pd.to_numeric, errors='coerce')\n",
        "print(test_data_HS.gender)\n",
        "test_data_psych.dropna(subset=['D1', 'D2', 'D3', 'D4', 'D5'], inplace=True)\n",
        "test_data_fipi.dropna(subset=['D1', 'D2', 'D3', 'D4', 'D5'], inplace=True)\n",
        "test_data_HS.dropna(subset=[\"gender\", \"age\",\"ethnicity\",\"label\"], inplace=True)\n",
        "print(test_data_HS.gender)\n",
        "\n",
        "test_data_HS.rename(\n",
        "    columns={\n",
        "        \"gender\":\"Gender_bin\",\n",
        "        \"age\":\"Age_bin\",\n",
        "        \"ethnicity\":\"Race_bin\"\n",
        "    },\n",
        "    inplace=True\n",
        ")\n",
        "\n",
        "test_data_HS = test_data_HS[~test_data_HS.text.str.contains(\"user user user\")]\n",
        "print(len(test_data_HS.text))\n",
        "\"\"\"\n",
        "### Demographic binarization assumptions\n",
        "\n",
        "- D1 (Age): Over/under 55\n",
        "- D2 (Gender): already binarized\n",
        "- D3 (Race): White/non-White\n",
        "- D4 (Education): College grad or higher yes/no\n",
        "- D5 (Income): $55k+ yes/no\n",
        "\"\"\"\n",
        "\n",
        "# first binarize all of our columns.\n",
        "test_data_fipi[\"Age_bin\"] = (test_data_fipi[\"D1\"] <= 38).astype(int)\n",
        "test_data_fipi[\"Gender_bin\"] = (test_data_fipi[\"D2\"] == 1).astype(int)\n",
        "test_data_fipi[\"Race_bin\"] = (test_data_fipi[\"D3\"] == 1).astype(int)\n",
        "test_data_fipi[\"Education_bin\"] = (test_data_fipi[\"D4\"] >= 5).astype(int)\n",
        "test_data_fipi[\"Income_bin\"] = (test_data_fipi[\"D5\"] >= 4).astype(int)\n",
        "\n",
        "test_data_psych[\"Age_bin\"] = (test_data_psych[\"D1\"] <= 38).astype(int)\n",
        "test_data_psych[\"Gender_bin\"] = (test_data_psych[\"D2\"] == 1).astype(int)\n",
        "test_data_psych[\"Race_bin\"] = (test_data_psych[\"D3\"] == 1).astype(int)\n",
        "test_data_psych[\"Education_bin\"] = (test_data_psych[\"D4\"] >= 5).astype(int)\n",
        "test_data_psych[\"Income_bin\"] = (test_data_psych[\"D5\"] >= 4).astype(int)\n",
        "\n",
        "# I should be able to calculate all intersections programmatically.\n",
        "\n",
        "column_names = [\"Age_bin\", \"Gender_bin\", \"Race_bin\", \"Education_bin\", \"Income_bin\"]\n",
        "\n",
        "combinations = []\n",
        "# two-way\n",
        "for aa in range(len(column_names)):\n",
        "  a = column_names[aa]\n",
        "  for bb in range(aa + 1, len(column_names)):\n",
        "    b = column_names[bb]\n",
        "    if a == b:\n",
        "      continue\n",
        "    combinations.append(a.split(\"_\")[0] + \"_\" + b.split(\"_\")[0])\n",
        "    for cc in range(bb + 1, len(column_names)):\n",
        "      c = column_names[cc]\n",
        "      if a == b or a == c or b == c:\n",
        "        continue\n",
        "      combinations.append(a.split(\"_\")[0] + \"_\" + b.split(\"_\")[0] + \"_\" + c.split(\"_\")[0])\n",
        "      for dd in range(cc + 1, len(column_names)):\n",
        "        d = column_names[dd]\n",
        "        if a == b or a == c or a == d or b == c or b == d or c == d:\n",
        "          continue\n",
        "        combinations.append(a.split(\"_\")[0] + \"_\" + b.split(\"_\")[0] + \"_\" + c.split(\"_\")[0] + \"_\" + d.split(\"_\")[0])\n",
        "\n",
        "combinations.append(\"Age_Gender_Race_Education_Income\")\n",
        "\n",
        "print(combinations)\n",
        "\n",
        "# this will be a fraction: what percentage of categories is someone in the privileged class?\n",
        "\n",
        "\n",
        "for comb in combinations:\n",
        "  columns = [a + \"_bin\" for a in comb.split(\"_\")]\n",
        "  test_data_psych[comb] = 0\n",
        "  for i in range(len(columns)):\n",
        "    test_data_psych[comb] += test_data_psych[columns[i]].astype(float)\n",
        "  test_data_psych[comb] = test_data_psych[comb] / len(columns)\n",
        "\n",
        "  test_data_fipi[comb] = 0\n",
        "  for i in range(len(columns)):\n",
        "    test_data_fipi[comb] += test_data_fipi[columns[i]].astype(float)\n",
        "  test_data_fipi[comb] = test_data_fipi[comb] / len(columns)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NJYava8MjS-W"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import pearsonr\n",
        "from sklearn.metrics import mean_squared_error, f1_score\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4SVjW-J_qPH8"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def generatePlots_v3(basefile, modelTask, textCol, full_N=False, gold_ratio=False):\n",
        "    frames = []\n",
        "\n",
        "    fname = basefile\n",
        "    bert_preds = pd.read_csv(fname, quotechar=\"\\\"\", encoding=\"utf-8\")\n",
        "    df = bert_preds\n",
        "\n",
        "    df[\"s1\"] = df[\"sentence\"]\n",
        "    if \"FIPI\" in basefile:\n",
        "      test_data = test_data_fipi\n",
        "    else:\n",
        "      test_data = test_data_psych\n",
        "    test_data[\"s1\"] = test_data[textCol]\n",
        "    D = df.merge(test_data, on=\"s1\", how=\"inner\")\n",
        "    print(\"start: \" + str(len(df[\"s1\"])))\n",
        "    print(\"merge: \" + str(len(D[\"s1\"])))\n",
        "\n",
        "    try:\n",
        "      D[\"probs\"] = D[\"preds\"]\n",
        "    except:\n",
        "      D[\"probs\"] = D[\"pred\"]\n",
        "\n",
        "    # For continuous, we'll use the stated label\n",
        "    # calculate median and use that as cutoff instead of 0.5\n",
        "    if \"Continuous\" in basefile:\n",
        "      labelColumn = textCol.replace(\"Text\", \"Label\")\n",
        "      median_val = statistics.median(D[labelColumn])\n",
        "      try:\n",
        "        print(D[\"label\"])\n",
        "      except:\n",
        "        D[\"label\"] = D[labelColumn]\n",
        "      D[\"probs_binarized\"] = D[\"probs\"].apply(lambda x: 0 if x < median_val else 1)\n",
        "      D[\"label_binarized\"] = D[\"label\"].apply(lambda x: 0 if x < median_val else 1)\n",
        "      print(median_val)\n",
        "    else:\n",
        "      D[\"probs_binarized\"] = D[\"probs\"].apply(lambda x: 0 if x < 0.5 else 1)\n",
        "      D[\"label_binarized\"] = D[\"label\"]\n",
        "\n",
        "    D2 = D\n",
        "\n",
        "    demogColumns = [\n",
        "                    \"Age_bin\", \"Gender_bin\", \"Race_bin\",\n",
        "        \"Education_bin\", \"Income_bin\", \"Age_Gender\", \"Age_Gender_Race\",\n",
        "        \"Age_Gender_Race_Education\", \"Age_Gender_Race_Income\",\n",
        "        \"Age_Gender_Education\", \"Age_Gender_Education_Income\",\n",
        "        \"Age_Gender_Income\", \"Age_Race\", \"Age_Race_Education\",\n",
        "        \"Age_Race_Education_Income\", \"Age_Race_Income\", \"Age_Education\",\n",
        "        \"Age_Education_Income\", \"Age_Income\", \"Gender_Race\",\n",
        "        \"Gender_Race_Education\", \"Gender_Race_Education_Income\",\n",
        "        \"Gender_Race_Income\", \"Gender_Education\", \"Gender_Education_Income\",\n",
        "        \"Gender_Income\", \"Race_Education\", \"Race_Education_Income\",\n",
        "        \"Race_Income\", \"Education_Income\", \"Age_Gender_Race_Education_Income\"\n",
        "    ]\n",
        "    DIs = []\n",
        "    demog_trues = []\n",
        "    FVs = []\n",
        "\n",
        "    # laplace smoothing to account for zeros\n",
        "    for dc in demogColumns:\n",
        "\n",
        "      positive_predictions = D2[\"probs_binarized\"]==1\n",
        "      positive_gold = D2[\"label_binarized\"]==1\n",
        "      protected = D2[dc]==0\n",
        "      privileged = D2[dc] == 1\n",
        "      N = 2\n",
        "      alpha = 1\n",
        "\n",
        "      DI_numerator = (sum(positive_predictions & protected) + alpha) / (sum(protected) + N)\n",
        "      DI_denominator =  (sum(positive_predictions & privileged) + alpha) / (sum(privileged) + N)\n",
        "\n",
        "      ytrue_numerator = (sum(positive_gold & protected) + alpha) / (sum(protected) + N)\n",
        "      ytrue_denominator =  (sum(positive_gold & privileged) + alpha) / (sum(privileged) + N)\n",
        "\n",
        "      ypred_global = (sum(positive_predictions) + alpha) / (len(D2[dc]) + N)\n",
        "\n",
        "\n",
        "      try:\n",
        "        DI = DI_numerator / DI_denominator\n",
        "        ytrue = ytrue_numerator / ytrue_denominator\n",
        "        FV = np.abs(DI_numerator - ypred_global)\n",
        "      except:\n",
        "        DI=0\n",
        "        ytrue=0\n",
        "        FV=0\n",
        "\n",
        "      if gold_ratio:\n",
        "          DI = DI / ytrue\n",
        "\n",
        "      DIs.append(DI)\n",
        "      FVs.append(FV)\n",
        "      demog_trues.append((dc, ytrue))\n",
        "\n",
        "    # auc from sklearn\n",
        "    fpr, tpr, _ = metrics.roc_curve(D2[\"label_binarized\"], D2[\"probs\"], pos_label=1)\n",
        "    auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "    # other metrics: MSE, pearson, F1\n",
        "    mse = mean_squared_error(D2[\"label\"], D2[\"probs\"])\n",
        "    pearsonscore, prob = pearsonr(D2[\"label\"], D2[\"probs\"])\n",
        "    f1score = f1_score(D2[\"label_binarized\"], D2[\"probs_binarized\"])\n",
        "\n",
        "    return [mse, pearsonscore, f1score, auc] + DIs + FVs, demog_trues\n",
        "\n",
        "\n",
        "\n",
        "def get_results(full_N, gold_ratio, models):\n",
        "    DIs, aucs, xaucs = [], [], []\n",
        "    task = []\n",
        "    dc_tracker = []\n",
        "    l = []\n",
        "    results = []\n",
        "    demog_trues = []\n",
        "\n",
        "    for basefname in models:\n",
        "      for i in range(len(modelTasks)):\n",
        "        m = modelTasks[i]\n",
        "        l.append(m)\n",
        "        print(i, textCols)\n",
        "        colname = textCols[i]\n",
        "        print(basefname, m, colname)\n",
        "        if m.lower() not in basefname.lower():\n",
        "          if 'FIPI' in basefname and m.lower() ==\"subjectivelit\":\n",
        "            m = \"SubjectiveLit\"\n",
        "          else:\n",
        "            continue\n",
        "        outs, dt = generatePlots_v3(basefname, m, colname, full_N, gold_ratio)\n",
        "        if len(demog_trues) == 0:\n",
        "          demog_trues.extend(dt)\n",
        "        modelname = basefname.split(\"/\")[1]\n",
        "        results.append([modelname, m] + outs)\n",
        "\n",
        "    colnames = [\"model\",\n",
        "              \"DV\",\n",
        "              \"MSE\", \"Pearson R\", \"F1\",\n",
        "              \"AUC\",\n",
        "        \"DI_Age_bin\", \"DI_Gender_bin\", \"DI_Race_bin\",\n",
        "        \"DI_Education_bin\", \"DI_Income_bin\", \"DI_Age_Gender\", \"DI_Age_Gender_Race\",\n",
        "        \"DI_Age_Gender_Race_Education\", \"DI_Age_Gender_Race_Income\",\n",
        "        \"DI_Age_Gender_Education\", \"DI_Age_Gender_Education_Income\",\n",
        "        \"DI_Age_Gender_Income\", \"DI_Age_Race\", \"DI_Age_Race_Education\",\n",
        "        \"DI_Age_Race_Education_Income\", \"DI_Age_Race_Income\", \"DI_Age_Education\",\n",
        "        \"DI_Age_Education_Income\", \"DI_Age_Income\", \"DI_Gender_Race\",\n",
        "        \"DI_Gender_Race_Education\", \"DI_Gender_Race_Education_Income\",\n",
        "        \"DI_Gender_Race_Income\", \"DI_Gender_Education\", \"DI_Gender_Education_Income\",\n",
        "        \"DI_Gender_Income\", \"DI_Race_Education\", \"DI_Race_Education_Income\",\n",
        "        \"DI_Race_Income\", \"DI_Education_Income\", \"DI_Age_Gender_Race_Education_Income\",\n",
        "        \"FV_Age_bin\", \"FV_Gender_bin\", \"FV_Race_bin\",\n",
        "        \"FV_Education_bin\", \"FV_Income_bin\", \"FV_Age_Gender\", \"FV_Age_Gender_Race\",\n",
        "        \"FV_Age_Gender_Race_Education\", \"FV_Age_Gender_Race_Income\",\n",
        "        \"FV_Age_Gender_Education\", \"FV_Age_Gender_Education_Income\",\n",
        "        \"FV_Age_Gender_Income\", \"FV_Age_Race\", \"FV_Age_Race_Education\",\n",
        "        \"FV_Age_Race_Education_Income\", \"FV_Age_Race_Income\", \"FV_Age_Education\",\n",
        "        \"FV_Age_Education_Income\", \"FV_Age_Income\", \"FV_Gender_Race\",\n",
        "        \"FV_Gender_Race_Education\", \"FV_Gender_Race_Education_Income\",\n",
        "        \"FV_Gender_Race_Income\", \"FV_Gender_Education\", \"FV_Gender_Education_Income\",\n",
        "        \"FV_Gender_Income\", \"FV_Race_Education\", \"FV_Race_Education_Income\",\n",
        "        \"FV_Race_Income\", \"FV_Education_Income\", \"FV_Age_Gender_Race_Education_Income\",\n",
        "    ]\n",
        "\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    df.columns = colnames\n",
        "\n",
        "    return df, demog_trues\n",
        "\n",
        "def calculate_fairness(infile, outfile, weighted=False, unionYN=False):\n",
        "\n",
        "  models = [infile]\n",
        "\n",
        "  output, demogs = get_results(\n",
        "    unionYN,\n",
        "    weighted,\n",
        "    models\n",
        "  )\n",
        "\n",
        "  debiasing, wordlists = outfile.split(\"_\")[:2]\n",
        "  wordlists = wordlists.split(\".\")[0]\n",
        "  output[\"model\"] = outfile\n",
        "  output[\"adjustedDI\"] = weighted\n",
        "  output[\"debiasing\"] = debiasing\n",
        "  output[\"wordlists\"] = wordlists\n",
        "  output[\"fullN\"] = unionYN\n",
        "\n",
        "  output.to_csv(f\"fairness_output_{outfile}_fullN_{unionYN}_goldRatio_{weighted}.csv\", index=False)\n",
        "  demog_df = pd.DataFrame(demogs, columns=[\"Demographic\", \"Y1_Ratio\"])\n",
        "  demog_df[\"model\"] = outfile\n",
        "  demog_df[\"ratio\"] = weighted\n",
        "\n",
        "  demog_df.to_csv(f\"y1_ratio_{outfile}_fullN_{unionYN}_goldRatio_{weighted}.csv\", index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EwUjw75w-N3X",
        "outputId": "f9e0c9aa-4bc9-4b60-b0c4-25a189866363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Continuous_PT_BERT_test.csv Anxiety Text_Anxiety\n",
            "start: 8395\n",
            "merge: 8366\n",
            "0       0.333300\n",
            "1       0.285700\n",
            "2       0.476200\n",
            "3       0.928571\n",
            "4       0.476200\n",
            "          ...   \n",
            "8361    0.190476\n",
            "8362    0.142857\n",
            "8363    0.190476\n",
            "8364    0.785700\n",
            "8365    0.666700\n",
            "Name: label, Length: 8366, dtype: float64\n",
            "0.52381\n",
            "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Continuous_PT_BERT_test.csv Numeracy Text_Numeracy\n",
            "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Continuous_PT_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
            "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Continuous_PT_BERT_test.csv TrustPhys Text_TrustPhys\n",
            "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Continuous_PT_BERT_test.csv Anxiety Text_Anxiety\n",
            "start: 8395\n",
            "merge: 8366\n",
            "0       0.333300\n",
            "1       0.285700\n",
            "2       0.476200\n",
            "3       0.928571\n",
            "4       0.476200\n",
            "          ...   \n",
            "8361    0.190476\n",
            "8362    0.142857\n",
            "8363    0.190476\n",
            "8364    0.785700\n",
            "8365    0.666700\n",
            "Name: label, Length: 8366, dtype: float64\n",
            "0.52381\n",
            "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Continuous_PT_BERT_test.csv Numeracy Text_Numeracy\n",
            "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Continuous_PT_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
            "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Continuous_PT_BERT_test.csv TrustPhys Text_TrustPhys\n",
            "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Continuous_PT_RoBERTa_test.csv Anxiety Text_Anxiety\n",
            "start: 8395\n",
            "merge: 8366\n",
            "0       0.333300\n",
            "1       0.285700\n",
            "2       0.476200\n",
            "3       0.928571\n",
            "4       0.476200\n",
            "          ...   \n",
            "8361    0.190476\n",
            "8362    0.142857\n",
            "8363    0.190476\n",
            "8364    0.785700\n",
            "8365    0.666700\n",
            "Name: label, Length: 8366, dtype: float64\n",
            "0.52381\n",
            "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Continuous_PT_RoBERTa_test.csv Numeracy Text_Numeracy\n",
            "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Continuous_PT_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
            "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Continuous_PT_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
            "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Continuous_PT_RoBERTa_test.csv Anxiety Text_Anxiety\n",
            "start: 8395\n",
            "merge: 8366\n",
            "0       0.333300\n",
            "1       0.285700\n",
            "2       0.476200\n",
            "3       0.928571\n",
            "4       0.476200\n",
            "          ...   \n",
            "8361    0.190476\n",
            "8362    0.142857\n",
            "8363    0.190476\n",
            "8364    0.785700\n",
            "8365    0.666700\n",
            "Name: label, Length: 8366, dtype: float64\n",
            "0.52381\n",
            "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Continuous_PT_RoBERTa_test.csv Numeracy Text_Numeracy\n",
            "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Continuous_PT_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
            "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Continuous_PT_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
            "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Continuous_PT_CNN_test.csv Anxiety Text_Anxiety\n",
            "start: 8395\n",
            "merge: 8302\n",
            "0.52381\n",
            "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Continuous_PT_CNN_test.csv Numeracy Text_Numeracy\n",
            "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Continuous_PT_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
            "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Continuous_PT_CNN_test.csv TrustPhys Text_TrustPhys\n",
            "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Continuous_PT_CNN_test.csv Anxiety Text_Anxiety\n",
            "start: 8395\n",
            "merge: 8302\n",
            "0.52381\n",
            "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Continuous_PT_CNN_test.csv Numeracy Text_Numeracy\n",
            "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Continuous_PT_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
            "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Continuous_PT_CNN_test.csv TrustPhys Text_TrustPhys\n",
            "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Binary_PT_BERT_test.csv Anxiety Text_Anxiety\n",
            "start: 8395\n",
            "merge: 8366\n",
            "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Binary_PT_BERT_test.csv Numeracy Text_Numeracy\n",
            "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Binary_PT_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
            "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Binary_PT_BERT_test.csv TrustPhys Text_TrustPhys\n",
            "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Binary_PT_BERT_test.csv Anxiety Text_Anxiety\n",
            "start: 8395\n",
            "merge: 8366\n",
            "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Binary_PT_BERT_test.csv Numeracy Text_Numeracy\n",
            "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Binary_PT_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
            "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Binary_PT_BERT_test.csv TrustPhys Text_TrustPhys\n",
            "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Binary_PT_RoBERTa_test.csv Anxiety Text_Anxiety\n",
            "start: 8395\n",
            "merge: 8366\n",
            "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Binary_PT_RoBERTa_test.csv Numeracy Text_Numeracy\n",
            "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Binary_PT_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
            "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Binary_PT_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
            "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Binary_PT_RoBERTa_test.csv Anxiety Text_Anxiety\n",
            "start: 8395\n",
            "merge: 8366\n",
            "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Binary_PT_RoBERTa_test.csv Numeracy Text_Numeracy\n",
            "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Binary_PT_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
            "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Binary_PT_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
            "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
            "/content/train/merged/Psychometric_Anxiety_Binary_PT_CNN_test.csv Anxiety Text_Anxiety\n",
            "start: 8395\n",
            "merge: 8302\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'preds'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-e61a6dd8614f>\u001b[0m in \u001b[0;36mgeneratePlots_v3\u001b[0;34m(basefile, modelTask, textCol, full_N, gold_ratio)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m       \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"preds\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3761\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'preds'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'pred'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-32b43d5d150d>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m               \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"/content/train/merged/{m}_{t}_{d}_{mm}_test.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m               \u001b[0moutname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{m}_{t}_{d}_{mm}_F_F_test.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m               \u001b[0mcalculate_fairness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munionYN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m               \u001b[0moutname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{m}_{t}_{d}_{mm}_T_F_test.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m               \u001b[0mcalculate_fairness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munionYN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-e61a6dd8614f>\u001b[0m in \u001b[0;36mcalculate_fairness\u001b[0;34m(infile, outfile, weighted, unionYN)\u001b[0m\n\u001b[1;32m    168\u001b[0m   \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m   output, demogs = get_results(\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0munionYN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mweighted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-e61a6dd8614f>\u001b[0m in \u001b[0;36mget_results\u001b[0;34m(full_N, gold_ratio, models)\u001b[0m\n\u001b[1;32m    124\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneratePlots_v3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasefname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_N\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemog_trues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m           \u001b[0mdemog_trues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-e61a6dd8614f>\u001b[0m in \u001b[0;36mgeneratePlots_v3\u001b[0;34m(basefile, modelTask, textCol, full_N, gold_ratio)\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"preds\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pred\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# For continuous, we'll use the stated label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3761\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'pred'"
          ]
        }
      ],
      "source": [
        "modelTasks = [\"Anxiety\", \"Numeracy\", \"SubjectiveLit\", \"TrustPhys\"]\n",
        "\n",
        "textCols = [\"Text_Anxiety\",\"Text_Numeracy\",\"Text_SubjectiveLit\",\"Text_TrustPhys\"]\n",
        "\n",
        "labelCols = [\"Label_Anxiety\",\"Label_Numeracy\",\"Label_SubjectiveLit\",\"Label_TrustPhys\"]\n",
        "taskNames = [\n",
        "            'Psychometric_Anxiety',\n",
        "            'Psychometric_Numeracy',\n",
        "            'Psychometric_SubjectiveLit',\n",
        "            'Psychometric_TrustPhys',\n",
        "            'FIPI_Extraverted',\n",
        "            'FIPI_Stable'\n",
        "]\n",
        "\n",
        "debiasing = [\n",
        "    \"PT\",\n",
        "    \"PTD\",\n",
        "    \"PTDCDA\",\n",
        "    \"PTDDropout\"\n",
        "]\n",
        "\n",
        "tasks = [\n",
        "    \"Continuous\",\n",
        "    \"Binary\"\n",
        "]\n",
        "\n",
        "models = [\n",
        "    \"BERT\",\n",
        "    \"RoBERTa\",\n",
        "    \"CNN\"\n",
        "]\n",
        "\n",
        "\n",
        "for m in taskNames:\n",
        "    for d in debiasing:\n",
        "        for t in tasks:\n",
        "          for mm in models:\n",
        "              fname = f\"/content/train/merged/{m}_{t}_{d}_{mm}_test.csv\"\n",
        "              outname = f\"{m}_{t}_{d}_{mm}_F_F_test.csv\"\n",
        "              calculate_fairness(fname, outname, weighted=False, unionYN=False)\n",
        "              outname = f\"{m}_{t}_{d}_{mm}_T_F_test.csv\"\n",
        "              calculate_fairness(fname, outname, weighted=True, unionYN=False)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JrHNWrcN5FL"
      },
      "source": [
        "# Ask a Patient Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BZ0fVsybNV7V"
      },
      "outputs": [],
      "source": [
        "def generatePlots_AAP(basefile, full_N=False, gold_ratio=False):\n",
        "    frames = []\n",
        "\n",
        "    fname = basefile\n",
        "    bert_preds = pd.read_csv(fname, quotechar=\"\\\"\", encoding=\"utf-8\")\n",
        "    D = bert_preds\n",
        "    df = D\n",
        "\n",
        "    if \"CNN\" in fname:\n",
        "      bertfile = fname.replace(\"CNN\", \"BERT\")\n",
        "      test_data = pd.read_csv(bertfile, quotechar=\"\\\"\", encoding=\"utf-8\")\n",
        "      D = df.merge(test_data, on=\"sentence\", how=\"inner\")\n",
        "      print(\"start: \" + str(len(df[\"sentence\"])))\n",
        "      print(\"merge: \" + str(len(D[\"sentence\"])))\n",
        "      try:\n",
        "        D[\"probs\"] = D[\"preds\"]\n",
        "      except:\n",
        "        D[\"probs\"] = D[\"pred\"]\n",
        "    else:\n",
        "      try:\n",
        "        D[\"probs\"] = D[\"preds\"]\n",
        "      except:\n",
        "        D[\"probs\"] = D[\"pred\"]\n",
        "\n",
        "    # For continuous, we'll use the stated label\n",
        "    # calculate median and use that as cutoff instead of 0.5\n",
        "    #median_val = 0.5\n",
        "    median_val = statistics.median(D[\"label\"])\n",
        "\n",
        "    D[\"probs_binarized\"] = D[\"probs\"].apply(lambda x: 0 if x < median_val else 1)\n",
        "    D[\"label_binarized\"] = D[\"label\"].apply(lambda x: 0 if x < median_val else 1)\n",
        "    print(median_val)\n",
        "    D2 = D.dropna()\n",
        "\n",
        "    demogColumns = [\n",
        "                    \"Age\", \"Gender\", \"Age_Gender\"\n",
        "    ]\n",
        "    DIs = []\n",
        "    FVs=[]\n",
        "    demog_trues = []\n",
        "    D2[\"Age\"] = (D2[\"x2\"] <= 56).astype(int)\n",
        "    D2[\"Gender\"] = (D2[\"x1\"] == \"M\").astype(int)\n",
        "    D2[\"Age_Gender\"] = (D2[\"Age\"].astype(int) + D2[\"Gender\"].astype(int)) / 2\n",
        "\n",
        "\n",
        "    for dc in demogColumns:\n",
        "\n",
        "      positive_predictions = D2[\"probs_binarized\"]==1\n",
        "      positive_gold = D2[\"label_binarized\"]==1\n",
        "      protected = D2[dc]==0\n",
        "      privileged = D2[dc] == 1\n",
        "      N = 2\n",
        "      alpha = 1\n",
        "\n",
        "      DI_numerator = (sum(positive_predictions & protected) + alpha) / (sum(protected) + N)\n",
        "      DI_denominator =  (sum(positive_predictions & privileged) + alpha) / (sum(privileged) + N)\n",
        "\n",
        "      ytrue_numerator = (sum(positive_gold & protected) + alpha) / (sum(protected) + N)\n",
        "      ytrue_denominator =  (sum(positive_gold & privileged) + alpha) / (sum(privileged) + N)\n",
        "      ypred_global = (sum(positive_predictions) + alpha) / (len(D2[dc]) + N)\n",
        "\n",
        "      DI = DI_numerator / DI_denominator\n",
        "      ytrue = ytrue_numerator / ytrue_denominator\n",
        "      FV = np.abs(DI_numerator - ypred_global)\n",
        "\n",
        "      if gold_ratio:\n",
        "          DI = DI / ytrue\n",
        "      print(dc)\n",
        "\n",
        "\n",
        "      DIs.append(DI)\n",
        "      FVs.append(FV)\n",
        "      demog_trues.append((dc, ytrue))\n",
        "\n",
        "    # auc from sklearn\n",
        "    fpr, tpr, _ = metrics.roc_curve(D2[\"label_binarized\"], D2[\"probs\"], pos_label=1)\n",
        "    auc = metrics.auc(fpr, tpr)\n",
        "    mse = mean_squared_error(D2[\"label\"], D2[\"probs\"])\n",
        "    pearsonscore, prob = pearsonr(D2[\"label\"], D2[\"probs\"])\n",
        "    f1score = f1_score(D2[\"label_binarized\"], D2[\"probs_binarized\"])\n",
        "\n",
        "    return [mse, pearsonscore, f1score, auc] + DIs+FVs, demog_trues\n",
        "\n",
        "\n",
        "def get_results_AAP(full_N, gold_ratio, models):\n",
        "    DIs, aucs, xaucs = [], [], []\n",
        "    task = []\n",
        "    dc_tracker = []\n",
        "    l = []\n",
        "    results = []\n",
        "    demog_trues = []\n",
        "\n",
        "    for basefname in models:\n",
        "        outs, dt = generatePlots_AAP(basefname, full_N, gold_ratio)\n",
        "        if len(demog_trues) == 0:\n",
        "          demog_trues.extend(dt)\n",
        "        modelname = basefname.split(\"/\")[1]\n",
        "        results.append([modelname, m] + outs)\n",
        "\n",
        "    colnames = [\"model\",\n",
        "              \"DV\",\n",
        "              \"MSE\", \"Pearson R\", \"F1\",\n",
        "              \"AUC\",\n",
        "        \"DI_Age\", \"DI_Gender\", \"DI_Age_Gender\",\n",
        "        \"FV_Age\", \"FV_Gender\", \"FV_Age_Gender\",\n",
        "    ]\n",
        "\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    df.columns = colnames\n",
        "\n",
        "    return df, demog_trues\n",
        "\n",
        "def calculate_fairness_AAP(infile, outfile, weighted=False, unionYN=False):\n",
        "\n",
        "  models = [infile]\n",
        "\n",
        "  output, demogs = get_results_AAP(\n",
        "    unionYN,\n",
        "    weighted,\n",
        "    models\n",
        "  )\n",
        "\n",
        "  debiasing, wordlists = outfile.split(\"_\")[:2]\n",
        "  wordlists = wordlists.split(\".\")[0]\n",
        "  output[\"model\"] = outfile\n",
        "  output[\"adjustedDI\"] = weighted\n",
        "  output[\"debiasing\"] = debiasing\n",
        "  output[\"wordlists\"] = wordlists\n",
        "  output[\"fullN\"] = unionYN\n",
        "\n",
        "  output.to_csv(f\"fairness_output_{outfile}_fullN_{unionYN}_goldRatio_{weighted}.csv\", index=False)\n",
        "  demog_df = pd.DataFrame(demogs, columns=[\"Demographic\", \"Y1_Ratio\"])\n",
        "  demog_df[\"model\"] = outfile\n",
        "  demog_df[\"ratio\"] = weighted\n",
        "\n",
        "  demog_df.to_csv(f\"y1_ratio_{outfile}_fullN_{unionYN}_goldRatio_{weighted}.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pXjevffENJyn",
        "outputId": "99d975b5-34bc-4b6c-8c31-930bec90cbf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6\n",
            "Age\n",
            "Gender\n",
            "Age_Gender\n",
            "0.6\n",
            "Age\n",
            "Gender\n",
            "Age_Gender\n",
            "0.6\n",
            "Age\n",
            "Gender\n",
            "Age_Gender\n",
            "0.6\n",
            "Age\n",
            "Gender\n",
            "Age_Gender\n",
            "start: 20000\n",
            "merge: 19915\n",
            "0.6\n",
            "Age\n",
            "Gender\n",
            "Age_Gender\n",
            "start: 20000\n",
            "merge: 19915\n",
            "0.6\n",
            "Age\n",
            "Gender\n",
            "Age_Gender\n",
            "0.0\n",
            "Age\n",
            "Gender\n",
            "Age_Gender\n",
            "0.0\n",
            "Age\n",
            "Gender\n",
            "Age_Gender\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py:1020: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py:1020: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "Age\n",
            "Gender\n",
            "Age_Gender\n",
            "0.0\n",
            "Age\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py:1020: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py:1020: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gender\n",
            "Age_Gender\n",
            "start: 20000\n",
            "merge: 19915\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'label'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d20d8652a570>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"/content/train/merged/{m}_{t}_{d}_{mm}_test.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0moutname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{m}_{t}_{d}_{mm}_F_F_test.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mcalculate_fairness_AAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munionYN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0moutname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{m}_{t}_{d}_{mm}_T_F_test.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mcalculate_fairness_AAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munionYN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-89251ae23d9f>\u001b[0m in \u001b[0;36mcalculate_fairness_AAP\u001b[0;34m(infile, outfile, weighted, unionYN)\u001b[0m\n\u001b[1;32m    116\u001b[0m   \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m   output, demogs = get_results_AAP(\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0munionYN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mweighted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-89251ae23d9f>\u001b[0m in \u001b[0;36mget_results_AAP\u001b[0;34m(full_N, gold_ratio, models)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbasefname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneratePlots_AAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasefname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_N\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemog_trues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m           \u001b[0mdemog_trues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-89251ae23d9f>\u001b[0m in \u001b[0;36mgeneratePlots_AAP\u001b[0;34m(basefile, full_N, gold_ratio)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# calculate median and use that as cutoff instead of 0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#median_val = 0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mmedian_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs_binarized\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmedian_val\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3761\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'label'"
          ]
        }
      ],
      "source": [
        "\n",
        "taskNames = [\n",
        "            'AskAPatient_AskAPatient'\n",
        "]\n",
        "\n",
        "debiasing = [\n",
        "    \"PT\",\n",
        "    \"PTD\"\n",
        "]\n",
        "\n",
        "tasks = [\n",
        "    \"Continuous\",\n",
        "    \"Binary\"\n",
        "]\n",
        "\n",
        "models = [\n",
        "    \"BERT\",\n",
        "    \"RoBERTa\",\n",
        "    \"CNN\"\n",
        "]\n",
        "\n",
        "\n",
        "for m in taskNames:\n",
        "    for d in debiasing:\n",
        "        for t in tasks:\n",
        "          for mm in models:\n",
        "            fname = f\"/content/train/merged/{m}_{t}_{d}_{mm}_test.csv\"\n",
        "            outname = f\"{m}_{t}_{d}_{mm}_F_F_test.csv\"\n",
        "            calculate_fairness_AAP(fname, outname, weighted=False, unionYN=False)\n",
        "            outname = f\"{m}_{t}_{d}_{mm}_T_F_test.csv\"\n",
        "            calculate_fairness_AAP(fname, outname, weighted=True, unionYN=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8CUDxovCLC7"
      },
      "source": [
        "# Hate Speech Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gl6Mo4pKCMbM"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generatePlots_HS(basefile, full_N=False, gold_ratio=False):\n",
        "    frames = []\n",
        "\n",
        "    fname = basefile\n",
        "    bert_preds = pd.read_csv(fname, quotechar=\"\\\"\", encoding=\"utf-8\")\n",
        "    df = bert_preds\n",
        "\n",
        "    df[\"s1\"] = df[\"sentence\"]\n",
        "    test_data = test_data_HS\n",
        "    test_data[\"s1\"] = test_data[\"text\"]\n",
        "    D = df.merge(test_data, on=\"s1\", how=\"inner\")\n",
        "    D.drop_duplicates(subset=[\"s1\"], inplace=True)\n",
        "    D[\"label\"] = D[\"label_y\"]\n",
        "    print(\"start: \" + str(len(df[\"s1\"])))\n",
        "    print(\"merge: \" + str(len(D[\"s1\"])))\n",
        "\n",
        "    try:\n",
        "      D[\"probs\"] = D[\"preds\"]\n",
        "    except:\n",
        "      try:\n",
        "        D[\"probs\"] = D[\"pred\"]\n",
        "      except:\n",
        "        D[\"probs\"] = D[\"probs\"]\n",
        "\n",
        "    # For continuous, we'll use the stated label\n",
        "    # calculate median and use that as cutoff instead of 0.5\n",
        "    median_val = 0.5\n",
        "    D[\"probs_binarized\"] = D[\"probs\"].apply(lambda x: 0 if float(x[1:-1]) < median_val else 1)\n",
        "    D[\"probs\"] = D[\"probs_binarized\"]\n",
        "    D[\"label_binarized\"] = D[\"label\"]\n",
        "    print(median_val)\n",
        "    D2 = D.dropna()\n",
        "\n",
        "    demogColumns = [\n",
        "                    \"Age_bin\", \"Gender_bin\", \"Race_bin\",\n",
        "        \"Age_Gender\", \"Age_Gender_Race\",\n",
        "        \"Age_Race\", \"Gender_Race\",\n",
        "    ]\n",
        "    DIs = []\n",
        "    FVs = []\n",
        "    demog_trues = []\n",
        "    D2[\"Age_Gender\"] = (D2[\"Age_bin\"].astype(int) + D2[\"Gender_bin\"].astype(int)) / 2\n",
        "    D2[\"Age_Race\"] = (D2[\"Age_bin\"].astype(int) + D2[\"Race_bin\"].astype(int)) / 2\n",
        "    D2[\"Gender_Race\"] = (D2[\"Gender_bin\"].astype(int) + D2[\"Race_bin\"].astype(int)) / 2\n",
        "    D2[\"Age_Gender_Race\"] = (D2[\"Age_bin\"].astype(int) + D2[\"Gender_bin\"].astype(int) + D2[\"Race_bin\"].astype(int)) / 3\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # laplace smoothing to account for zeros\n",
        "    for dc in demogColumns:\n",
        "\n",
        "      positive_predictions = D2[\"probs_binarized\"]==1\n",
        "      positive_gold = D2[\"label_binarized\"]==1\n",
        "      protected = D2[dc]==0\n",
        "      privileged = D2[dc] == 1\n",
        "      N = 2\n",
        "      alpha = 1\n",
        "\n",
        "      DI_numerator = (sum(positive_predictions & protected) + alpha) / (sum(protected) + N)\n",
        "      DI_denominator =  (sum(positive_predictions & privileged) + alpha) / (sum(privileged) + N)\n",
        "\n",
        "      ytrue_numerator = (sum(positive_gold & protected) + alpha) / (sum(protected) + N)\n",
        "      ytrue_denominator =  (sum(positive_gold & privileged) + alpha) / (sum(privileged) + N)\n",
        "      ypred_global = (sum(positive_predictions) + alpha) / (len(D2[dc]) + N)\n",
        "\n",
        "      try:\n",
        "        DI = DI_numerator / DI_denominator\n",
        "        ytrue = ytrue_numerator / ytrue_denominator\n",
        "        FV = np.abs(DI_numerator - ypred_global)\n",
        "      except:\n",
        "        DI=0\n",
        "        ytrue=0\n",
        "        FV=0\n",
        "\n",
        "      if gold_ratio:\n",
        "          DI = DI / ytrue\n",
        "      print(dc)\n",
        "\n",
        "\n",
        "      DIs.append(DI)\n",
        "      FVs.append(FV)\n",
        "      demog_trues.append((dc, ytrue))\n",
        "\n",
        "    # auc from sklearn\n",
        "    fpr, tpr, _ = metrics.roc_curve(D2[\"label_binarized\"], D2[\"probs\"], pos_label=1)\n",
        "    auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "    # other metrics: MSE, pearson, F1\n",
        "    mse = 0\n",
        "    pearsonscore, prob = 0, 0\n",
        "    f1score = f1_score(D2[\"label_binarized\"], D2[\"probs_binarized\"])\n",
        "\n",
        "    return [mse, pearsonscore, f1score, auc] + DIs + FVs, demog_trues\n",
        "\n",
        "\n",
        "\n",
        "def get_results_HS(full_N, gold_ratio, models):\n",
        "    DIs, aucs, xaucs = [], [], []\n",
        "    task = []\n",
        "    dc_tracker = []\n",
        "    l = []\n",
        "    results = []\n",
        "    demog_trues = []\n",
        "\n",
        "    for basefname in models:\n",
        "        outs, dt = generatePlots_HS(basefname, full_N, gold_ratio)\n",
        "        if len(demog_trues) == 0:\n",
        "          demog_trues.extend(dt)\n",
        "        modelname = basefname.split(\"/\")[1]\n",
        "        results.append([modelname, m] + outs)\n",
        "\n",
        "    colnames = [\"model\",\n",
        "              \"DV\",\n",
        "              \"MSE\", \"Pearson R\", \"F1\",\n",
        "              \"AUC\",\n",
        "        \"DI_Age_bin\", \"DI_Gender_bin\", \"DI_Race_bin\",\n",
        "        \"DI_Age_Gender\", \"DI_Age_Gender_Race\",\n",
        "        \"DI_Age_Race\", \"DI_Gender_Race\",\n",
        "        \"FV_Age_bin\", \"FV_Gender_bin\", \"FV_Race_bin\",\n",
        "        \"FV_Age_Gender\", \"FV_Age_Gender_Race\",\n",
        "        \"FV_Age_Race\", \"FV_Gender_Race\",\n",
        "    ]\n",
        "\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    df.columns = colnames\n",
        "\n",
        "    return df, demog_trues\n",
        "\n",
        "def calculate_fairness_HS(infile, outfile, weighted=False, unionYN=False):\n",
        "\n",
        "  models = [infile]\n",
        "\n",
        "  output, demogs = get_results_HS(\n",
        "    unionYN,\n",
        "    weighted,\n",
        "    models\n",
        "  )\n",
        "\n",
        "  debiasing, wordlists = outfile.split(\"_\")[:2]\n",
        "  wordlists = wordlists.split(\".\")[0]\n",
        "  output[\"model\"] = outfile\n",
        "  output[\"adjustedDI\"] = weighted\n",
        "  output[\"debiasing\"] = debiasing\n",
        "  output[\"wordlists\"] = wordlists\n",
        "  output[\"fullN\"] = unionYN\n",
        "\n",
        "  output.to_csv(f\"fairness_output_{outfile}_fullN_{unionYN}_goldRatio_{weighted}.csv\", index=False)\n",
        "  demog_df = pd.DataFrame(demogs, columns=[\"Demographic\", \"Y1_Ratio\"])\n",
        "  demog_df[\"model\"] = outfile\n",
        "  demog_df[\"ratio\"] = weighted\n",
        "\n",
        "  demog_df.to_csv(f\"y1_ratio_{outfile}_fullN_{unionYN}_goldRatio_{weighted}.csv\", index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "coOK4pEmCQ-L",
        "outputId": "1f630781-9e09-4bcb-8e26-8c2093eb263f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start: 83077\n",
            "merge: 38583\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-d2f658a8be8b>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"/content/train/merged/{m}_{t}_{d}_{mm}_test.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0moutname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{m}_{t}_{d}_{mm}_F_F_test.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mcalculate_fairness_HS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munionYN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0moutname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{m}_{t}_{d}_{mm}_T_F_test.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mcalculate_fairness_HS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munionYN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-ac3c989b5317>\u001b[0m in \u001b[0;36mcalculate_fairness_HS\u001b[0;34m(infile, outfile, weighted, unionYN)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m   output, demogs = get_results_HS(\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0munionYN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mweighted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-ac3c989b5317>\u001b[0m in \u001b[0;36mget_results_HS\u001b[0;34m(full_N, gold_ratio, models)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbasefname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneratePlots_HS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasefname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_N\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemog_trues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m           \u001b[0mdemog_trues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-ac3c989b5317>\u001b[0m in \u001b[0;36mgeneratePlots_HS\u001b[0;34m(basefile, full_N, gold_ratio)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# calculate median and use that as cutoff instead of 0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mmedian_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs_binarized\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmedian_val\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs_binarized\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label_binarized\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4628\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4629\u001b[0m         \"\"\"\n\u001b[0;32m-> 4630\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4632\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1077\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-ac3c989b5317>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# calculate median and use that as cutoff instead of 0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mmedian_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs_binarized\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmedian_val\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs_binarized\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label_binarized\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "\n",
        "taskNames = [\n",
        "            'Hatespeech_Hatespeech'\n",
        "]\n",
        "\n",
        "debiasing = [\n",
        "    \"PT\",\n",
        "    \"PTD\"\n",
        "]\n",
        "\n",
        "tasks = [\n",
        "    \"Binary\"\n",
        "]\n",
        "\n",
        "models = [\n",
        "    \"BERT\",\n",
        "    \"RoBERTa\",\n",
        "    \"CNN\"\n",
        "]\n",
        "\n",
        "\n",
        "for m in taskNames:\n",
        "    for d in debiasing:\n",
        "        for t in tasks:\n",
        "          for mm in models:\n",
        "            fname = f\"/content/train/merged/{m}_{t}_{d}_{mm}_test.csv\"\n",
        "            outname = f\"{m}_{t}_{d}_{mm}_F_F_test.csv\"\n",
        "            calculate_fairness_HS(fname, outname, weighted=False, unionYN=False)\n",
        "            outname = f\"{m}_{t}_{d}_{mm}_T_F_test.csv\"\n",
        "            calculate_fairness_HS(fname, outname, weighted=True, unionYN=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoM0e8mpbz6G"
      },
      "source": [
        "# MBTI Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "cLFkZOm4by-V"
      },
      "outputs": [],
      "source": [
        "def generatePlots_MBTI(basefile, full_N=False, gold_ratio=False):\n",
        "    frames = []\n",
        "\n",
        "    fname = basefile\n",
        "    bert_preds = pd.read_csv(fname, quotechar=\"\\\"\", encoding=\"utf-8\")\n",
        "    df = bert_preds\n",
        "\n",
        "    df[\"s1\"] = df[\"sentence\"]\n",
        "    D = df\n",
        "    if \"CNN\" in fname:\n",
        "      bertfile = fname.replace(\"CNN\", \"BERT\")\n",
        "      test_data = pd.read_csv(bertfile, quotechar=\"\\\"\", encoding=\"utf-8\")\n",
        "      D = df.merge(test_data, on=\"sentence\", how=\"inner\")\n",
        "      D[\"label\"] = D[\"label_y\"]\n",
        "      print(\"start: \" + str(len(df[\"s1\"])))\n",
        "      print(\"merge: \" + str(len(D[\"s1\"])))\n",
        "    else:\n",
        "      try:\n",
        "        D[\"probs\"] = D[\"preds\"]\n",
        "      except:\n",
        "        D[\"probs\"] = D[\"pred\"]\n",
        "\n",
        "    # For continuous, we'll use the stated label\n",
        "    # calculate median and use that as cutoff instead of 0.5\n",
        "    median_val = 0.5\n",
        "    D[\"probs\"] = D[\"probs\"].apply(lambda x: float(x[1:-1]))\n",
        "    D[\"probs_binarized\"] = D[\"probs\"].apply(lambda x: 0 if x < median_val else 1)\n",
        "    D[\"label_binarized\"] = D[\"label\"]\n",
        "    print(median_val)\n",
        "    D2 = D.dropna()\n",
        "\n",
        "    demogColumns = [\n",
        "        \"Age_bin\", \"Gender_bin\",\n",
        "        \"Age_Gender\"\n",
        "    ]\n",
        "    DIs = []\n",
        "    FVs = []\n",
        "    demog_trues = []\n",
        "    D2[\"Gender_bin\"] = (D2[\"x1\"] == \"m\").astype(int)\n",
        "    D2[\"Age_bin\"] = (D2[\"x2\"] < 55).astype(int)\n",
        "    D2[\"Age_Gender\"] = (D2[\"Age_bin\"].astype(int) + D2[\"Gender_bin\"].astype(int)) / 2\n",
        "\n",
        "    # laplace smoothing to account for zeros\n",
        "    for dc in demogColumns:\n",
        "\n",
        "      positive_predictions = D2[\"probs_binarized\"]==1\n",
        "      positive_gold = D2[\"label_binarized\"]==1\n",
        "      protected = D2[dc]==0\n",
        "      privileged = D2[dc] == 1\n",
        "      N = 2\n",
        "      alpha = 1\n",
        "\n",
        "      DI_numerator = (sum(positive_predictions & protected) + alpha) / (sum(protected) + N)\n",
        "      DI_denominator =  (sum(positive_predictions & privileged) + alpha) / (sum(privileged) + N)\n",
        "\n",
        "      ytrue_numerator = (sum(positive_gold & protected) + alpha) / (sum(protected) + N)\n",
        "      ytrue_denominator =  (sum(positive_gold & privileged) + alpha) / (sum(privileged) + N)\n",
        "      ypred_global = (sum(positive_predictions) + alpha) / (len(D2[dc]) + N)\n",
        "\n",
        "      try:\n",
        "        DI = DI_numerator / DI_denominator\n",
        "        ytrue = ytrue_numerator / ytrue_denominator\n",
        "        FV = np.abs(DI_numerator - ypred_global)\n",
        "      except:\n",
        "        DI=0\n",
        "        ytrue=0\n",
        "        FV=0\n",
        "\n",
        "      if gold_ratio:\n",
        "          DI = DI / ytrue\n",
        "      print(dc)\n",
        "\n",
        "\n",
        "      DIs.append(DI)\n",
        "      FVs.append(FV)\n",
        "      demog_trues.append((dc, ytrue))\n",
        "\n",
        "    # auc from sklearn\n",
        "    fpr, tpr, _ = metrics.roc_curve(D2[\"label_binarized\"], D2[\"probs\"], pos_label=1)\n",
        "    auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "    # other metrics: MSE, pearson, F1\n",
        "    mse = 0\n",
        "    pearsonscore, prob = 0, 0\n",
        "    f1score = f1_score(D2[\"label_binarized\"], D2[\"probs_binarized\"])\n",
        "\n",
        "    return [mse, pearsonscore, f1score, auc] + DIs + FVs, demog_trues\n",
        "\n",
        "\n",
        "\n",
        "def get_results_MBTI(full_N, gold_ratio, models):\n",
        "    DIs, aucs, xaucs = [], [], []\n",
        "    task = []\n",
        "    dc_tracker = []\n",
        "    l = []\n",
        "    results = []\n",
        "    demog_trues = []\n",
        "\n",
        "    for basefname in models:\n",
        "        outs, dt = generatePlots_MBTI(basefname, full_N, gold_ratio)\n",
        "        if len(demog_trues) == 0:\n",
        "          demog_trues.extend(dt)\n",
        "        modelname = basefname.split(\"/\")[1]\n",
        "        results.append([modelname, m] + outs)\n",
        "\n",
        "    colnames = [\"model\",\n",
        "              \"DV\",\n",
        "              \"MSE\", \"Pearson R\", \"F1\",\n",
        "              \"AUC\",\n",
        "        \"DI_Age_bin\", \"DI_Gender_bin\",\n",
        "        \"DI_Age_Gender\",\n",
        "        \"FV_Age_bin\", \"FV_Gender_bin\",\n",
        "        \"FV_Age_Gender\",\n",
        "    ]\n",
        "\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    df.columns = colnames\n",
        "\n",
        "    return df, demog_trues\n",
        "\n",
        "def calculate_fairness_MBTI(infile, outfile, weighted=False, unionYN=False):\n",
        "\n",
        "  models = [infile]\n",
        "\n",
        "  output, demogs = get_results_MBTI(\n",
        "    unionYN,\n",
        "    weighted,\n",
        "    models\n",
        "  )\n",
        "\n",
        "  debiasing, wordlists = outfile.split(\"_\")[:2]\n",
        "  wordlists = wordlists.split(\".\")[0]\n",
        "  output[\"model\"] = outfile\n",
        "  output[\"adjustedDI\"] = weighted\n",
        "  output[\"debiasing\"] = debiasing\n",
        "  output[\"wordlists\"] = wordlists\n",
        "  output[\"fullN\"] = unionYN\n",
        "\n",
        "  output.to_csv(f\"fairness_output_{outfile}_fullN_{unionYN}_goldRatio_{weighted}.csv\", index=False)\n",
        "  demog_df = pd.DataFrame(demogs, columns=[\"Demographic\", \"Y1_Ratio\"])\n",
        "  demog_df[\"model\"] = outfile\n",
        "  demog_df[\"ratio\"] = weighted\n",
        "\n",
        "  demog_df.to_csv(f\"y1_ratio_{outfile}_fullN_{unionYN}_goldRatio_{weighted}.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "SzpfZKsLeDzq",
        "outputId": "47082eb4-6ca2-43ba-a309-2d5c06b4d84c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-6829fa94693f>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"/content/train/merged/{m}_{t}_{d}_{mm}_test.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0moutname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{m}_{t}_{d}_{mm}_F_F_test.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mcalculate_fairness_MBTI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munionYN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0moutname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{m}_{t}_{d}_{mm}_T_F_test.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mcalculate_fairness_MBTI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munionYN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-d80a097ae933>\u001b[0m in \u001b[0;36mcalculate_fairness_MBTI\u001b[0;34m(infile, outfile, weighted, unionYN)\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m   output, demogs = get_results_MBTI(\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0munionYN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mweighted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-d80a097ae933>\u001b[0m in \u001b[0;36mget_results_MBTI\u001b[0;34m(full_N, gold_ratio, models)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbasefname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneratePlots_MBTI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasefname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_N\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemog_trues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m           \u001b[0mdemog_trues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-d80a097ae933>\u001b[0m in \u001b[0;36mgeneratePlots_MBTI\u001b[0;34m(basefile, full_N, gold_ratio)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# calculate median and use that as cutoff instead of 0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmedian_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs_binarized\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmedian_val\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label_binarized\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4628\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4629\u001b[0m         \"\"\"\n\u001b[0;32m-> 4630\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4632\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1077\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-d80a097ae933>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# calculate median and use that as cutoff instead of 0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmedian_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs_binarized\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmedian_val\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label_binarized\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "taskNames = [\n",
        "            'MBTI_perceiving',\n",
        "             'MBTI_thinking',\n",
        "]\n",
        "\n",
        "debiasing = [\n",
        "    \"PT\",\n",
        "    \"PTD\"\n",
        "]\n",
        "\n",
        "tasks = [\n",
        "    \"Binary\"\n",
        "]\n",
        "\n",
        "models = [\n",
        "    \"BERT\",\n",
        "    \"RoBERTa\",\n",
        "    \"CNN\"\n",
        "]\n",
        "\n",
        "\n",
        "for m in taskNames:\n",
        "    for d in debiasing:\n",
        "        for t in tasks:\n",
        "          for mm in models:\n",
        "            fname = f\"/content/train/merged/{m}_{t}_{d}_{mm}_test.csv\"\n",
        "            outname = f\"{m}_{t}_{d}_{mm}_F_F_test.csv\"\n",
        "            calculate_fairness_MBTI(fname, outname, weighted=False, unionYN=False)\n",
        "            outname = f\"{m}_{t}_{d}_{mm}_T_F_test.csv\"\n",
        "            calculate_fairness_MBTI(fname, outname, weighted=True, unionYN=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5aM0or61JgI"
      },
      "outputs": [],
      "source": [
        "# concatenate everything together\n",
        "!head -n 1 fairness_output_FIPI_Agreeable_Continuous_PT_BERT_F_F_test.csv_fullN_False_goldRatio_False.csv > results_bert_acl22_Psych_FIPI.csv\n",
        "!head -n 1 fairness_output_Hatespeech_Hatespeech_Binary_PT_BERT_F_F_test.csv_fullN_False_goldRatio_False.csv > results_bert_acl22_HS.csv\n",
        "!head -n 1 fairness_output_AskAPatient_AskAPatient_Continuous_PT_BERT_F_F_test.csv_fullN_False_goldRatio_False.csv > results_bert_acl22_AAP.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gq9NsWLuja1w"
      },
      "outputs": [],
      "source": [
        "!head -n 1 fairness_output_MBTI_perceiving_Binary_PT_CNN_F_F_test.csv_fullN_False_goldRatio_False.csv > results_bert_acl22_MBTI.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGMVaPgR2rLK"
      },
      "outputs": [],
      "source": [
        "!head results_bert_acl22*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Y57gD072tgH"
      },
      "outputs": [],
      "source": [
        "!tail -n 1 -q fairness_output_FIPI* >> results_bert_acl22_Psych_FIPI.csv\n",
        "!tail -n 1 -q fairness_output_Psych* >> results_bert_acl22_Psych_FIPI.csv\n",
        "!tail -n 1 -q fairness_output_Ha* >> results_bert_acl22_HS.csv\n",
        "!tail -n 1 -q fairness_output_Ask* >> results_bert_acl22_AAP.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwsLk4I8jfo0"
      },
      "outputs": [],
      "source": [
        "!tail -n 1 -q fairness_output_MBTI* >> results_bert_acl22_MBTI.csv"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}